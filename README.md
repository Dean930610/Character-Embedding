# Character-Embedding
This section mainly focuses on how to generate a character based word embedding based on Bi-LSTM based model. Most of the popular word embedding model generating methods mainly focus on the relationship between center words and surrouding words such as CBOW and Skip-gram methods. Word embedding vectors generated by these methods have been widely used in many NLP related practical works. Characeter embedding could represent the order of letters which might be important in some specific tasks. In many practical applicaiton, character based word embedding normally used with word embedding vectors together for seeking higher performance.  
In this section, a Bi-LSTM based neural network model will be used to acquire the character based word embedding. The target of this model is the word embedding vector of input words, and the inputs will be the sequencing letters of input word represented by one-hot encoding. After the neural network model reaching convergency, the hidden state of 
### Main Procedure
#### 1. Data Pre-processing



